{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LM VAE - VAE in text\n",
    "\n",
    "Lets go through the evolution of Language Variational Autoencoders , from their foundational concepts to modern, scalable frameworks. We will explore:\n",
    "\n",
    "- High-level background of VAE\n",
    "\n",
    "- Traditional VAE for Text Generation: Understanding the initial approach and its inherent challenges.\n",
    "\n",
    "\n",
    "- LM-VAE (Optimus): How VAEs were scaled up using large pre-trained language models.\n",
    "\n",
    "\n",
    "- LangVAE and LangSpace: Modern, modular frameworks for building and probing LM-VAEs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0 - high-level background of VAE\n",
    "\n",
    "\n",
    "A Variational Autoencoder (VAE) is a type of generative neural network that learns to create new data similar to what it was trained on.\n",
    "\n",
    "![](./VAE.png)\n",
    "\n",
    "The input data, denoted as **x**, is first passed through a probabilistic encoder, which is a neural network that compresses the data into a lower-dimensional representation. Instead of outputting a single vector, the encoder produces two vectors: a mean vector **μ** and a standard deviation vector **σ**. These vectors parameterize a probability distribution in the latent space, from which a latent vector **z** is sampled using a random variable **ε** in a process called the reparameterization trick. \n",
    "\n",
    "\n",
    "\n",
    "This sampled latent vector **z** is then fed into a probabilistic decoder, another neural network, which aims to reconstruct the original input. The model's training process minimizes both the reconstruction error between the output **x'** and the original input **x**, and the difference between the learned latent distribution and a standard normal distribution. \n",
    "\n",
    "\n",
    "For generative inference after training, one can discard the encoder, sample a random vector **z** from the latent space, and use the decoder to synthesize entirely new data points.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMwOdayuroAl"
   },
   "source": [
    "## Part 1: Generating Sentences from a Continuous Space – The Genesis of Language VAEs\n",
    "\n",
    "![Generating Sentences from a Continuous Space](./1stPaper.png)\n",
    "\n",
    "\n",
    "- Problem: Standard recurrent neural network language models (RNNLMs) generate text word-by-word, lacking an explicit, global representation of the entire sentence. The model is like someone writing a story word by word, not knowing where it's going, similar to telling a joke without knowing the punchline.\n",
    "\n",
    "\n",
    "- Solution: Introduce a Variational Autoencoder (VAE) for sentences to explicitly model holistic properties like style, topic, and high-level syntactic features.\n",
    "\n",
    "\n",
    "\n",
    "- VAE Benefits: \n",
    "\n",
    "![Standard encoder-decoder VS VAE in text interpolation.](./StandardVSvae.png)\n",
    "\n",
    "\n",
    "![](./disentanglement.png)\n",
    "\n",
    "By imposing a prior distribution (typically a standard Gaussian) on the latent space, **the model learns a smooth and structured representation of sentences**. \n",
    "\n",
    "### The VAE Model Architecture\n",
    "\n",
    "The model consists of two main components: an **Encoder** and a **Decoder**, both of which are Recurrent Neural Networks (RNNs), specifically LSTMs in this implementation.\n",
    "\n",
    "\n",
    "![Figure 1](./paper1figure1.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Posterior collapse\n",
    "\n",
    "The decoder is an autoregressive model that generates new word each step at a time when each new word is predicted based on all the words that came before that.\n",
    "\n",
    "Sometimes the decoder becomes so effective at predecting the next word using only the previous words that it **learns to completely ignore the latent code z**.\n",
    "\n",
    "Since the decoder ignores z, the **encoder has no incentive to encode useful information from the input sentence x**.\n",
    "\n",
    "Therefore the model finds a trivial solution and it sets the KL divergence term to zero by making the posterior distribution q(z|x) identical to the prior p(z) to every input sentence x.\n",
    "\n",
    "The result is a \"collapsed\" latent space. **The model fails to learn a meaningful, continuous representation of sentences**.\n",
    "\n",
    "\n",
    "#### solutions proposed in the paper\n",
    "\n",
    "![KL Cost Annealing](./KLannealing.png)\n",
    "\n",
    "* ***KL Cost Annealing***: We start training with the KL divergence weight beta set to **0 and gradually increase it to 1**. So at first the encoder is forced to encode necessary information into z so the **decoder can reconstruct the input and rely on z for that**. Then the slowly increase of beta towards 1 introduces the regulariation pressure, **encouraging the model to organize the latent space to resemble the prior**.\n",
    "\n",
    "* **Word Dropout**: In training we randomly replace the ground truth previous words in the decoder's input with an `<unk>` token. This weakens the decoder, **forcing it to rely more on the latent vector `z`** to make accurate predictions.\n",
    "\n",
    "![](./elbo2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Pytorch Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from TraditionalVAEcheckPoints.utils import to_var\n",
    "\n",
    "\n",
    "class SentenceVAE(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, rnn_type, hidden_size, word_dropout, embedding_dropout, latent_size,\n",
    "                sos_idx, eos_idx, pad_idx, unk_idx, max_sequence_length, num_layers=1, bidirectional=False):\n",
    "\n",
    "        super().__init__()\n",
    "        self.tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.Tensor\n",
    "        \n",
    "        # שמירת כל ההיפר-פרמטרים והאינדקסים החשובים\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.sos_idx = sos_idx\n",
    "        self.eos_idx = eos_idx\n",
    "        self.pad_idx = pad_idx\n",
    "        self.unk_idx = unk_idx\n",
    "\n",
    "        self.latent_size = latent_size\n",
    "        self.rnn_type = rnn_type\n",
    "        self.bidirectional = bidirectional\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # שכבת הembedding הפיכת מילים לווקטורים\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.word_dropout_rate = word_dropout\n",
    "        self.embedding_dropout = nn.Dropout(p=embedding_dropout)\n",
    "\n",
    "        # לב המודל: שכבות הRNN\n",
    "        if rnn_type == 'rnn':\n",
    "            rnn = nn.RNN\n",
    "        elif rnn_type == 'gru':\n",
    "            rnn = nn.GRU\n",
    "        elif rnn_type == 'lstm':\n",
    "            rnn = nn.LSTM\n",
    "        else:\n",
    "            raise ValueError()\n",
    "\n",
    "        self.encoder_rnn = rnn(embedding_size, hidden_size, num_layers=num_layers, bidirectional=self.bidirectional,\n",
    "                               batch_first=True)\n",
    "        self.decoder_rnn = rnn(embedding_size, hidden_size, num_layers=num_layers, bidirectional=self.bidirectional,\n",
    "                               batch_first=True)\n",
    "        self.hidden_factor = (2 if bidirectional else 1) * num_layers\n",
    "\n",
    "\n",
    "        # הקשר בין הencoder לdecoder בVAE\n",
    "        self.hidden2mean = nn.Linear(hidden_size * self.hidden_factor, latent_size)\n",
    "        self.hidden2logv = nn.Linear(hidden_size * self.hidden_factor, latent_size)\n",
    "        self.latent2hidden = nn.Linear(latent_size, hidden_size * self.hidden_factor)\n",
    "\n",
    "        #שכבת הפלט\n",
    "        self.outputs2vocab = nn.Linear(hidden_size * (2 if bidirectional else 1), vocab_size)\n",
    "\n",
    "    def forward(self, input_sequence, length):\n",
    "\n",
    "        batch_size = input_sequence.size(0)\n",
    "            \n",
    "        input_embedding = self.embedding(input_sequence)\n",
    "\n",
    "        # Pack the sequences so the RNN can ignore the padding tokens\n",
    "        sorted_lengths, sorted_idx = torch.sort(length, descending=True)\n",
    "        input_sequence = input_sequence[sorted_idx]\n",
    "        packed_input = rnn_utils.pack_padded_sequence(input_embedding, sorted_lengths.data.tolist(), batch_first=True)\n",
    "\n",
    "        _, hidden = self.encoder_rnn(packed_input)\n",
    "\n",
    "        if self.bidirectional or self.num_layers > 1:\n",
    "            # flatten hidden state\n",
    "            hidden = hidden.view(batch_size, self.hidden_size*self.hidden_factor)\n",
    "        else:\n",
    "            hidden = hidden.squeeze()\n",
    "\n",
    "        # REPARAMETERIZATION TRICK\n",
    "        mean = self.hidden2mean(hidden)\n",
    "        logv = self.hidden2logv(hidden)\n",
    "        std = torch.exp(0.5 * logv)\n",
    "        epsilon = to_var(torch.randn([batch_size, self.latent_size]))\n",
    "        z = epsilon * std + mean\n",
    "\n",
    "        \n",
    "        hidden = self.latent2hidden(z)\n",
    "\n",
    "        if self.bidirectional or self.num_layers > 1:\n",
    "            # unflatten hidden state\n",
    "            hidden = hidden.view(self.hidden_factor, batch_size, self.hidden_size)\n",
    "        else:\n",
    "            hidden = hidden.unsqueeze(0)\n",
    "\n",
    "        # Word Dropout (for the posterior issue)\n",
    "        if self.word_dropout_rate > 0:\n",
    "            # randomly replace decoder input with <unk>\n",
    "            prob = torch.rand(input_sequence.size())\n",
    "            if torch.cuda.is_available():\n",
    "                prob=prob.cuda()\n",
    "            prob[(input_sequence.data - self.sos_idx) * (input_sequence.data - self.pad_idx) == 0] = 1\n",
    "            decoder_input_sequence = input_sequence.clone()\n",
    "            decoder_input_sequence[prob < self.word_dropout_rate] = self.unk_idx\n",
    "            input_embedding = self.embedding(decoder_input_sequence)\n",
    "            \n",
    "        input_embedding = self.embedding_dropout(input_embedding)\n",
    "        packed_input = rnn_utils.pack_padded_sequence(input_embedding, sorted_lengths.data.tolist(), batch_first=True)\n",
    "\n",
    "        # decoder forward pass\n",
    "        outputs, _ = self.decoder_rnn(packed_input, hidden)\n",
    "        padded_outputs = rnn_utils.pad_packed_sequence(outputs, batch_first=True)[0]\n",
    "        padded_outputs = padded_outputs.contiguous()\n",
    "        _,reversed_idx = torch.sort(sorted_idx)\n",
    "        padded_outputs = padded_outputs[reversed_idx]\n",
    "        b,s,_ = padded_outputs.size()\n",
    "\n",
    "        # project outputs to distribution over vocabulary\n",
    "        logp = nn.functional.log_softmax(self.outputs2vocab(padded_outputs.view(-1, padded_outputs.size(2))), dim=-1)\n",
    "        logp = logp.view(b, s, self.embedding.num_embeddings)\n",
    "\n",
    "        return logp, mean, logv, z\n",
    "\n",
    "    def inference(self, n=4, z=None):\n",
    "\n",
    "        if z is None:\n",
    "            batch_size = n\n",
    "            z = to_var(torch.randn([batch_size, self.latent_size]))\n",
    "        else:\n",
    "            batch_size = z.size(0)\n",
    "\n",
    "        # Create hidden state from latent variable z (for decoder)\n",
    "        hidden = self.latent2hidden(z)\n",
    "        if self.bidirectional or self.num_layers > 1:\n",
    "            hidden = hidden.view(self.hidden_factor, batch_size, self.hidden_size)\n",
    "        hidden = hidden.unsqueeze(0)\n",
    "\n",
    "        # Below variable are used for efficient generation of sentences (for dynamic stopping)\n",
    "        sequence_idx = torch.arange(0, batch_size, out=self.tensor()).long()\n",
    "        sequence_running = torch.arange(0, batch_size, out=self.tensor()).long()\n",
    "        sequence_mask = torch.ones(batch_size, out=self.tensor()).bool()\n",
    "        running_seqs = torch.arange(0, batch_size, out=self.tensor()).long()\n",
    "\n",
    "        generations = self.tensor(batch_size, self.max_sequence_length).fill_(self.pad_idx).long()\n",
    "\n",
    "        t = 0\n",
    "        while t < self.max_sequence_length and len(running_seqs) > 0:\n",
    "            # First token is SOS\n",
    "            if t == 0:\n",
    "                input_sequence = to_var(torch.Tensor(batch_size).fill_(self.sos_idx).long())\n",
    "            \n",
    "            input_sequence = input_sequence.unsqueeze(1)\n",
    "            input_embedding = self.embedding(input_sequence)\n",
    "            output, hidden = self.decoder_rnn(input_embedding, hidden)\n",
    "            logits = self.outputs2vocab(output)\n",
    "            input_sequence = self._sample(logits)\n",
    "\n",
    "            # save the word at position t\n",
    "            generations = self._save_sample(generations, input_sequence, sequence_running, t)\n",
    "\n",
    "\n",
    "            # update the dynamic stopping variables\n",
    "            sequence_mask[sequence_running] = (input_sequence != self.eos_idx)\n",
    "            sequence_running = sequence_idx.masked_select(sequence_mask)\n",
    "            running_mask = (input_sequence != self.eos_idx).data\n",
    "            running_seqs = running_seqs.masked_select(running_mask)\n",
    "            if len(running_seqs) > 0:\n",
    "                input_sequence = input_sequence[running_seqs]\n",
    "                hidden = hidden[:, running_seqs]\n",
    "                running_seqs = torch.arange(0, len(running_seqs), out=self.tensor()).long()\n",
    "\n",
    "            t += 1\n",
    "\n",
    "        return generations, z\n",
    "\n",
    "    def _sample(self, dist, mode='greedy'):\n",
    "\n",
    "        if mode == 'greedy':\n",
    "            _, sample = torch.topk(dist, 1, dim=-1)\n",
    "        sample = sample.reshape(-1)\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def _save_sample(self, save_to, sample, running_seqs, t):\n",
    "        # select only still running\n",
    "        running_latest = save_to[running_seqs]\n",
    "        # update token at position t\n",
    "        running_latest[:,t] = sample.data\n",
    "        # save back\n",
    "        save_to[running_seqs] = running_latest\n",
    "\n",
    "        return save_to\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reparameterization Trick\n",
    "![](./Reparameterization_Trick.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LM-VAE: Optimus\n",
    "\n",
    "\n",
    "![OPTIMUS: Organizing Sentences via Pre-trained Modeling of a Latent Space](./paper2.png)\n",
    "\n",
    "### Introduction\n",
    "\n",
    "**What will happen if we scale up a VAE and use it as a new pre-trained language model (PLM)?**. \n",
    "\n",
    "![](./deep_latent.png)\n",
    "\n",
    "Optimus is the first large-scale deep latent variable model for natural language \n",
    "\n",
    "### Architecture \n",
    "\n",
    "![Architecture](./optimus_architecture.png)\n",
    "\n",
    "We initialize encoder with BERT and initialize decoder with GPT-2.\n",
    "\n",
    "\n",
    "![BERT Architecture](./Bert_arch.png)\n",
    "\n",
    "Reminder: $T_{i}$ is the embedding of the word $tok_{i}$ , and an embedding is a numerical representation (vector) of that word meaning in its specific context.  \n",
    "\n",
    "The CLS token in bert final output is a rich, context aware summary of the entire input sentence x therfore it is used to obtain the latent variable z.\n",
    "\n",
    "\n",
    "![Latent vector injection](./latent_integration.png)\n",
    "\n",
    "To facilitate z in GPT-2 decoding without re-training the weights from scratch we can use 2 schemes:\n",
    "1) Memory scheme\n",
    "2) Embedding scheme\n",
    "\n",
    "\n",
    "Memory scheme:\n",
    "\n",
    "![Causal self-attention mechanism](./causal_self_attention.png)\n",
    "\n",
    "![](./transformer_memory.jpeg)\n",
    "![](./self_attention_matrix_calculation.png)\n",
    "\n",
    "(a) GPT-2 \"memory\" is an inherent part of its causal self-attention mechanism. \"Memory\" is the context window of previous tokens that the model is allowed to \"look back\" for each new word in generates.\n",
    "\n",
    "For every self attention layer we compute a new memory vector $h^{l}_{mem}$ by computing $zW_{M}$ when z is the latent vector and $W_{M}$ is the new learned matrix.\n",
    "\n",
    "Then $h^{l}_{mem}$ is added as a new column to K and new row to V in every step of the generation.\n",
    "\n",
    "![](./bert_embedding.png)\n",
    "\n",
    "(b) First we transform the latent vector z by a new weight matrix $W_{D}$ the resulting vector is added with element wise addition to the standard transformer embedding (token/BPE+positional embedding). \n",
    "\n",
    "\n",
    "**Comparison:**\n",
    "\n",
    "| Feature              | Memory Injection                                           | Embedding Injection                                |\n",
    "|----------------------|------------------------------------------------------------|----------------------------------------------------|\n",
    "| Concept              | $\\mathbf{z}$ as memory vector for attention                | $\\mathbf{z}$ added to token embeddings             |\n",
    "| Integration Point    | All layers via attention                                   | Input embedding layer                              |\n",
    "| Strength             | Persistent global conditioning                             | Early influence on generation                      |\n",
    "| Efficacy             | More effective empirically                                 | Less effective                                     |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9ca3ac",
   "metadata": {},
   "source": [
    "## LangVAE and LangSpace A Modern, Modular Framework\n",
    "\n",
    "![](./langvae_paper.png)\n",
    "\n",
    "*LangVAE* is a novel framework for building Variational Autoencoders (VAEs) on top of pre-trained LLMs. \n",
    "\n",
    "*LangVAE* offers a flexible and modular way to combine different encoder and decoder models.\n",
    "\n",
    "\n",
    "These representations can then be analyzed and manipulated using its companion framework, *LangSpace*.\n",
    "\n",
    "### LangVAE Novel Solution\n",
    "\n",
    "While standard Optimus training is E2E training meaning that the\n",
    "\n",
    "1) encoder projection layer\n",
    "2) memory and embedding layers\n",
    "\n",
    "are jointly trained with the base encoder and decoder to \"weld\" the new layers with the pre-trained model.\n",
    "\n",
    "LangVAE design is different, it use the KV cache injection mechanism that is compatible with a wide range of models. \n",
    "\n",
    "![](./KVcache.png)\n",
    "\n",
    "A key advantage of this approach that it dosen't require modifiying the decoder's architecture. This allows the weights of the PLM encoder and decoder to kept frozen during training. \n",
    "\n",
    "As a result training is much faster with less resources. They achieved parameter reduction of over 95%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780b64ac",
   "metadata": {},
   "source": [
    "### Training with LangVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d11ec476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/topazfreizeit/miniforge3/envs/lm-vae/lib/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "Loading dataset cache at ag_news_train_tok-gpt2_cache.jsonl: 66258it [00:00, 81418.15it/s]\n",
      "Loading dataset cache at ag_news_eval_tok-gpt2_cache.jsonl: 10it [00:00, 9181.93it/s]\n",
      "Checking train dataset...\n",
      "Checking eval dataset...\n",
      "Using Base Trainer\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Training ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model passed sanity check !\n",
      "Ready for training.\n",
      "\n",
      "Created ag_news-langvae-bert-gpt2-128/VAE_training_2025-06-20_03-24-10. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Training params:\n",
      " - max_epochs: 5\n",
      " - per_device_train_batch_size: 50\n",
      " - per_device_eval_batch_size: 50\n",
      " - checkpoint saving every: 500\n",
      "Optimizer: AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0.01\n",
      ")\n",
      "Scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x46672f410>\n",
      "\n",
      "Successfully launched training !\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e1bf893a1594cf9b0902f8cc16da8fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training of epoch 1/5:   0%|          | 0/2160 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c08579b9552430bad0771fe22c64e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval of epoch 1/5:   0%|          | 0/240 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "Train loss: 1718.6916\n",
      "Eval loss: 1451.1828\n",
      "--------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a0a976be01f4494a96978d3f5188a62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training of epoch 2/5:   0%|          | 0/2160 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e9bb16d04da4392b13df5896b2d9ea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval of epoch 2/5:   0%|          | 0/240 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "Train loss: 1439.8797\n",
      "Eval loss: 1458.5375\n",
      "--------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1be3313f1e24a3ea7c7c6ed32ba9db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training of epoch 3/5:   0%|          | 0/2160 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a658efdcc6941a6a93211987d66ab1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval of epoch 3/5:   0%|          | 0/240 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "Train loss: 1311.1592\n",
      "Eval loss: 1498.7332\n",
      "--------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8bff142b66f4735b2bb9ee189c430bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training of epoch 4/5:   0%|          | 0/2160 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a0123c04264e7199ef25767b224911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval of epoch 4/5:   0%|          | 0/240 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "Train loss: 1202.0847\n",
      "Eval loss: 1517.0797\n",
      "--------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab77d1e5dd874b689772f59ccd00b14d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training of epoch 5/5:   0%|          | 0/2160 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daad98acd4554f4f8fba32bd4abf1ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval of epoch 5/5:   0%|          | 0/240 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "Train loss: 1111.3661\n",
      "Eval loss: 1559.536\n",
      "--------------------------------------------------------------------------\n",
      "Training ended!\n",
      "Saved final model in ag_news-langvae-bert-gpt2-128/VAE_training_2025-06-20_03-24-10/final_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Finished ---\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from pythae.models.vae import VAEConfig\n",
    "from langvae import LangVAE\n",
    "from langvae.encoders import SentenceEncoder\n",
    "from langvae.decoders import SentenceDecoder\n",
    "from langvae.data_conversion.tokenization import TokenizedDataSet\n",
    "from langvae.pipelines import LanguageTrainingPipeline\n",
    "from langvae.trainers import CyclicalScheduleKLThresholdTrainerConfig\n",
    "from langvae.trainers.training_callbacks import TensorBoardCallback\n",
    "import torch._dynamo\n",
    "\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "LATENT_SIZE = 128\n",
    "MAX_SENT_LEN = 16\n",
    "\n",
    "# Load pre-trained sentence encoder and decoder models.\n",
    "decoder = SentenceDecoder(\"gpt2\", LATENT_SIZE, MAX_SENT_LEN, device=DEVICE, device_map=\"auto\")\n",
    "encoder = SentenceEncoder(\"bert-base-cased\", LATENT_SIZE, decoder.tokenizer, caching=True, device=DEVICE)\n",
    "\n",
    "\n",
    "# Load the ag_news dataset\n",
    "raw_datasets = load_dataset(\"ag_news\", split='train').train_test_split(test_size=0.1)\n",
    "\n",
    "# Extract the text sentences for training and evaluation\n",
    "train_texts = sorted(raw_datasets['train']['text'], key=len, reverse=True)\n",
    "eval_texts = sorted(raw_datasets['test']['text'], key=len, reverse=True)\n",
    "\n",
    "# Set training and evaluation datasets with auto tokenization.\n",
    "train_dataset = TokenizedDataSet(train_texts,\n",
    "                                 decoder.tokenizer, decoder.max_len, caching=True,\n",
    "                                 cache_persistence=f\"ag_news_train_tok-gpt2_cache.jsonl\")\n",
    "eval_dataset = TokenizedDataSet(eval_texts,\n",
    "                                decoder.tokenizer, decoder.max_len, caching=True,\n",
    "                                cache_persistence=f\"ag_news_eval_tok-gpt2_cache.jsonl\")\n",
    "\n",
    "# Define VAE model configuration\n",
    "model_config = VAEConfig(latent_dim=LATENT_SIZE)\n",
    "\n",
    "# Initialize LangVAE model\n",
    "model = LangVAE(model_config, encoder, decoder)\n",
    "\n",
    "exp_label = f\"ag_news-langvae-bert-gpt2-{LATENT_SIZE}\"\n",
    "\n",
    "# --- MODIFICATION 2: Configure Checkpoint Saving ---\n",
    "# The `output_dir` parameter tells the trainer where to save checkpoints.\n",
    "# `steps_saving` defines how often (in training steps) to save a checkpoint.\n",
    "training_config = CyclicalScheduleKLThresholdTrainerConfig(\n",
    "    output_dir=exp_label,  # Checkpoints will be saved in this directory\n",
    "    num_epochs=5,\n",
    "    learning_rate=1e-3,\n",
    "    per_device_train_batch_size=50,\n",
    "    per_device_eval_batch_size=50,\n",
    "    steps_saving=500,  # Save a checkpoint every 500 steps\n",
    "    optimizer_cls=\"AdamW\",\n",
    "    scheduler_cls=\"ReduceLROnPlateau\",\n",
    "    scheduler_params={\"patience\": 5, \"factor\": 0.5},\n",
    "    max_beta=1.0,\n",
    "    n_cycles=16,\n",
    "    target_kl=2.0,\n",
    "    keep_best_on_train=True\n",
    ")\n",
    "\n",
    "pipeline = LanguageTrainingPipeline(\n",
    "    training_config=training_config,\n",
    "    model=model\n",
    ")\n",
    "\n",
    "# Monitor the training progress with `tensorboard --logdir=runs &`\n",
    "tb_callback = TensorBoardCallback(exp_label)\n",
    "\n",
    "# The pipeline will now automatically save checkpoints to the 'output_dir'\n",
    "print(\"--- Starting Training ---\")\n",
    "pipeline(\n",
    "    train_data=train_dataset,\n",
    "    eval_data=eval_dataset,\n",
    "    callbacks=[tb_callback]\n",
    ")\n",
    "print(\"--- Training Finished ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2186fb63",
   "metadata": {},
   "source": [
    "## LangSpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import nltk\n",
    "from langvae import LangVAE\n",
    "from saf_datasets import EntailmentBankDataSet\n",
    "from langspace.probe import DisentanglementProbe\n",
    "from langspace.metrics.disentanglement import DisentanglementMetric as Metric\n",
    "from langspace.probe import InterpolationProbe\n",
    "from langspace.metrics.interpolation import InterpolationMetric as InterpMetric\n",
    "from saf.importers import ListImporter\n",
    "\n",
    "# Load annotated data from saf_datasets.\n",
    "dataset_example = EntailmentBankDataSet.from_resource(\"pos+lemma+ctag+dep+srl#expl_only-noreps\")\n",
    "annotations = {\"srl_f\": dataset_example.annotations[\"srl\"]}\n",
    "\n",
    "# The 'srl' annotation contains a list with the role of a single token in each phrase in the sentence.\n",
    "# 'srl_f' will contain the first non-empty srl annotation for each token.\n",
    "for sent in dataset_example:\n",
    "    for token in sent.tokens:\n",
    "        srl = token.annotations[\"srl\"]\n",
    "        token_annot = [lbl for lbl in srl if (lbl != \"O\")][0] if (len(set(srl)) > 1) else srl[0]\n",
    "        token.annotations[\"srl_f\"] = token_annot\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load pre trained LangVAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading LangVAE files for rebuilding...\n",
      "/Users/topazfreizeit/miniforge3/envs/lm-vae/lib/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "Successfully downloaded LangVAE model!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LangVAE(\n",
       "  (decoder): SentenceDecoder(\n",
       "    (context_hidden): ModuleList(\n",
       "      (0-11): 12 x LazyLinear(in_features=0, out_features=50688, bias=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): SentenceEncoder(\n",
       "    (linear): LazyLinear(in_features=0, out_features=256, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load explanation LM-VAE for generation.\n",
    "model = LangVAE.load_from_hf_hub(\"neuro-symbolic-ai/eb-langcvae-bert-base-cased-gpt2-srl-l128\") # Loads model from HuggingFace Hub.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/topazfreizeit/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/topazfreizeit/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/Users/topazfreizeit/miniforge3/envs/lm-vae/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:378: FutureWarning: `BatchEncoding.words()` property is deprecated and should be replaced with the identical, but more self-explanatory `BatchEncoding.word_ids()` property.\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "if (torch.cuda.is_available()):\n",
    "  model.encoder.to(\"cuda\")\n",
    "  model.decoder.to(\"cuda\")\n",
    "  model.encoder.init_pretrained_model()\n",
    "  model.decoder.init_pretrained_model()\n",
    "\n",
    "# Probing latent interpolation\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "sentences = [\n",
    "    (\"humans require freshwater for survival\", \"B-ARG0 B-V B-ARG1 B-ARGM-PRP I-ARGM-PRP\"),\n",
    "    (\"animals require food to survive\", \"B-ARG0 B-V B-ARG1 B-ARGM-PRP I-ARGM-PRP\"),\n",
    "    (\"the sun is in the northern hemisphere\", \"B-ARG0 I-ARG0 B-V B-ARGM-LOC I-ARGM-LOC I-ARGM-LOC I-ARGM-LOC\"),\n",
    "    (\"food is a source of energy for animals / plants\", \"B-ARG0 B-V B-ARG2 I-ARG2 I-ARG2 I-ARG2 B-ARGM-PRP I-ARGM-PRP\")\n",
    "]\n",
    "sentences_ds = ListImporter(annotations=[\"srl_f\"])([[(tok, lbl) for tok, lbl in zip(sent[0].split(), sent[1].split())] for sent in sentences]).sentences\n",
    "\n",
    "\n",
    "interp_dataset = [(sentences_ds[0], sentences_ds[1]), (sentences_ds[2], sentences_ds[3])]\n",
    "\n",
    "interp_report = InterpolationProbe(model, interp_dataset, eval=[InterpMetric.SMOOTHNESS], annotations=annotations).report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################\n",
      "  source: humans require freshwater for survival\n",
      "  target: animals require food to survive\n",
      "  distance: 0.9457203847853638\n",
      "generate\n",
      " humans require to water\n",
      " humans require food water\n",
      " humans require food water\n",
      " humans require food for survive\n",
      " humans require food to survive\n",
      " animals require food to survive\n",
      " animals require food to survive\n",
      " animals require food to survive\n",
      " animals require food to survive\n",
      " animals require food to survive\n",
      " animals require food to survive\n",
      "\n",
      "########################\n",
      "  source: the sun is in the northern hemisphere\n",
      "  target: food is a source of energy for animals\n",
      "  distance: 0.49064225131560396\n",
      "generate\n",
      " the sun is located in the northern sun\n",
      " the sun is located in the northern hemisphere\n",
      " the sun is located in the northern hemisphere\n",
      " the sun is located in the solar system\n",
      " the sun is located in the solar system\n",
      " the sun is a source in the solar\n",
      " the sun is a source of energy\n",
      " the sun is a source of energy\n",
      " food is a source of energy for plants\n",
      " food is a source of energy for plants\n",
      " food is a source of energy for plants\n",
      "\n",
      "########################\n"
     ]
    }
   ],
   "source": [
    "for idx, row in interp_report.iterrows():\n",
    "    print(f\"########################\")\n",
    "    for col, val in row.items():\n",
    "        if col == \"generate\":\n",
    "            print(col)\n",
    "            print(f\"{val}\")\n",
    "            continue\n",
    "        print(f\"  {col}: {val}\")\n",
    "    print()  # Blank line between rows\n",
    "\n",
    "print(f\"########################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arithmetic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/topazfreizeit/miniforge3/envs/lm-vae/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:378: FutureWarning: `BatchEncoding.words()` property is deprecated and should be replaced with the identical, but more self-explanatory `BatchEncoding.word_ids()` property.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               source  \\\n",
      "0                      Earth revolves around the sun.   \n",
      "1   the earth revolving around the sun causes star...   \n",
      "2   Its position appears to shift relative to the ...   \n",
      "3   stars appear to move relative to the horizon d...   \n",
      "4   the earth rotating on its axis causes stars to...   \n",
      "..                                                ...   \n",
      "70                          earth is a kind of planet   \n",
      "71  a complete rotation of the earth on earth 's a...   \n",
      "72                                 season of the year   \n",
      "73                           Earth turns on its axis.   \n",
      "74  summer is when a hemisphere is tilted towards ...   \n",
      "\n",
      "                                               target   op  \\\n",
      "0                      leo is a kind of constellation  sum   \n",
      "1                      a constellation contains stars  sum   \n",
      "2                 earth is a kind of celestial object  sum   \n",
      "3   a star is a kind of celestial object / celesti...  sum   \n",
      "4   apparent motion is when an object appears to m...  sum   \n",
      "..                                                ...  ...   \n",
      "70                         Earth rotating on its axis  avg   \n",
      "71                         1 day is equal to 24 hours  avg   \n",
      "72  new york state is a state located in the unite...  avg   \n",
      "73                                             winter  avg   \n",
      "74            the south pole is tilted toward the sun  avg   \n",
      "\n",
      "                                             generate  \n",
      "0                            Mars is a kind of planet  \n",
      "1                      a celestial align stars to sun  \n",
      "2                      Earth is a kind shift relative  \n",
      "3    a moonlight to a brightness causes star / cel...  \n",
      "4    apparent motion is when an object in the same...  \n",
      "..                                                ...  \n",
      "70                               Earth is on its axis  \n",
      "71   the complete revolution of the earth takes 1 ...  \n",
      "72   the is a the stateCTATATA OF OFTATATA The\\n\\n...  \n",
      "73                                    sun\\n\\n\\n\\n\\n\\n  \n",
      "74            the south pole is tilted toward the sun  \n",
      "\n",
      "[75 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "from langspace.probe import ArithmeticProbe\n",
    "from langspace.probe.arithmetic import ArithmeticOps\n",
    "\n",
    "\n",
    "op_dataset = [\n",
    "    (\"animals require food for survival\", \"animals require warmth for survival\"),\n",
    "    (\"water vapor is invisible\", \"the water is warm\")\n",
    "]\n",
    "op_dataset = [(dataset_example[i], dataset_example[i+1]) for i in range(0, 50, 2)]\n",
    "arith_report = ArithmeticProbe(model, op_dataset, ops=list(ArithmeticOps), annotations=annotations).report()\n",
    "print(arith_report)\n",
    "arith_report.to_csv(\"arithm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: Earth revolves around the sun.\n",
      "\n",
      "target: leo is a kind of constellation\n",
      "\n",
      "op: sum\n",
      "\n",
      "generate:  Mars is a kind of planet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample = arith_report.iloc[0]\n",
    "for col, val in sample.items():\n",
    "    print(f\"{col}: {val}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "lm-vae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "043c12178d154e10a87588d0cbe7666d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe48b3bf2d4c449e88aa79b0a313203d",
      "max": 18585438,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_53830910b7f4465085c4b18fd330bf2c",
      "value": 18585438
     }
    },
    "0a24cd35df284de385831c8191f8a43e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "256a77ed4bb345cbbef184b15dfacea8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4969a88178bb4e489b22ac6da556adf8",
      "placeholder": "​",
      "style": "IPY_MODEL_28e3413642814519a967ff9bc6adbd03",
      "value": "train-00000-of-00001.parquet: 100%"
     }
    },
    "26b947215eef41e78406667c7cf63620": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d1e2f650b2f47feaf2a9e349a5e103d",
      "placeholder": "​",
      "style": "IPY_MODEL_8086f74240f84043afabbf36f6277e2b",
      "value": " 1.23M/1.23M [00:00&lt;00:00, 37.3MB/s]"
     }
    },
    "28e3413642814519a967ff9bc6adbd03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3419ebcad0e74fb48ada92284c305cb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "345f06b3df1c46b5ae982686603a82c9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4160bf804f7d41978479ececcdb5ead6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "438031d66b2d4bc4846cc29124b2c805": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dafa62879ff740a08be81c2b4a3b6c12",
       "IPY_MODEL_b4fb7abcbe3b49928b0584197fc71cb2",
       "IPY_MODEL_9c75435c03c544e289b88d700bec1f34"
      ],
      "layout": "IPY_MODEL_ed13342b126a4d61842de0f906d0f069"
     }
    },
    "4573d53e61a84798aba5f74f2c78712a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e7e8ee504c99473b9289d9e0765c0948",
       "IPY_MODEL_a7cc56e39c724e9085cacf19621ca87d",
       "IPY_MODEL_ec3eb8fb9c55466a92782b7f21d20c22"
      ],
      "layout": "IPY_MODEL_988ac94a5665453b8ac3155b75adc574"
     }
    },
    "4969a88178bb4e489b22ac6da556adf8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "53830910b7f4465085c4b18fd330bf2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "55a52a83c0be4651be7d768d69813ca6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56ecea955dd24a56abad0292985a6bf0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d1e2f650b2f47feaf2a9e349a5e103d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62d0b01f5ab04f08bcc0c0a86263bc8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "737c0edbcda744598f910849c9046d6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "761e2a23616b4cee9c36608d223f1e74": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aa26a823520745408e22384ecce3af8e",
      "placeholder": "​",
      "style": "IPY_MODEL_0a24cd35df284de385831c8191f8a43e",
      "value": "test-00000-of-00001.parquet: 100%"
     }
    },
    "7719046268934522b023f0062fd57333": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8086f74240f84043afabbf36f6277e2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8522f87b5c22416cb3e1086b11fb6cc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "958365e9374043b6929b7b6ad210a6e8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "964fa7f286a042fd9e6fffe99b51ad92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_761e2a23616b4cee9c36608d223f1e74",
       "IPY_MODEL_f8fd4b7fd2b44408b51465c9958e0dfe",
       "IPY_MODEL_26b947215eef41e78406667c7cf63620"
      ],
      "layout": "IPY_MODEL_958365e9374043b6929b7b6ad210a6e8"
     }
    },
    "988ac94a5665453b8ac3155b75adc574": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c75435c03c544e289b88d700bec1f34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f1cc3d1fd7644fa89f67d2c199017672",
      "placeholder": "​",
      "style": "IPY_MODEL_d383a7bfeb3a4468a45c7af7d0689e9a",
      "value": " 7600/7600 [00:00&lt;00:00, 78886.74 examples/s]"
     }
    },
    "a7cc56e39c724e9085cacf19621ca87d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c075aa13c929416096b85d9bb77cdac8",
      "max": 120000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8522f87b5c22416cb3e1086b11fb6cc0",
      "value": 120000
     }
    },
    "aa26a823520745408e22384ecce3af8e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aa810ffaf6b14356bd02fa2863cc3b73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b13b88c97d57436397d43fa4e32a9168": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b4fb7abcbe3b49928b0584197fc71cb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4160bf804f7d41978479ececcdb5ead6",
      "max": 7600,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b13b88c97d57436397d43fa4e32a9168",
      "value": 7600
     }
    },
    "c075aa13c929416096b85d9bb77cdac8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c26e322cf30c4272bf1376072fd02059": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca39da28d49749ce82adb06a4b686a81": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d383a7bfeb3a4468a45c7af7d0689e9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dafa62879ff740a08be81c2b4a3b6c12": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c26e322cf30c4272bf1376072fd02059",
      "placeholder": "​",
      "style": "IPY_MODEL_3419ebcad0e74fb48ada92284c305cb9",
      "value": "Generating test split: 100%"
     }
    },
    "dcecf7db419c412c8e058817c322897c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7719046268934522b023f0062fd57333",
      "placeholder": "​",
      "style": "IPY_MODEL_62d0b01f5ab04f08bcc0c0a86263bc8e",
      "value": " 18.6M/18.6M [00:00&lt;00:00, 34.1MB/s]"
     }
    },
    "e7e8ee504c99473b9289d9e0765c0948": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ca39da28d49749ce82adb06a4b686a81",
      "placeholder": "​",
      "style": "IPY_MODEL_aa810ffaf6b14356bd02fa2863cc3b73",
      "value": "Generating train split: 100%"
     }
    },
    "ec3eb8fb9c55466a92782b7f21d20c22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_56ecea955dd24a56abad0292985a6bf0",
      "placeholder": "​",
      "style": "IPY_MODEL_737c0edbcda744598f910849c9046d6a",
      "value": " 120000/120000 [00:00&lt;00:00, 335308.58 examples/s]"
     }
    },
    "ed13342b126a4d61842de0f906d0f069": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1cc3d1fd7644fa89f67d2c199017672": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8fd4b7fd2b44408b51465c9958e0dfe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_55a52a83c0be4651be7d768d69813ca6",
      "max": 1234829,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fbcc556150d446e38fe12d7723e7c71e",
      "value": 1234829
     }
    },
    "faa595317e954f22bde3096a8d98add3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_256a77ed4bb345cbbef184b15dfacea8",
       "IPY_MODEL_043c12178d154e10a87588d0cbe7666d",
       "IPY_MODEL_dcecf7db419c412c8e058817c322897c"
      ],
      "layout": "IPY_MODEL_345f06b3df1c46b5ae982686603a82c9"
     }
    },
    "fbcc556150d446e38fe12d7723e7c71e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fe48b3bf2d4c449e88aa79b0a313203d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "state": {}
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
